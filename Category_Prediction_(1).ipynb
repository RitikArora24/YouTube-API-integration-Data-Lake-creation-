{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RitikArora24/YouTube-API-integration-Data-Lake-creation-/blob/main/Category_Prediction_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing all neccessary libraries"
      ],
      "metadata": {
        "id": "rA99K5oJ0XV9"
      },
      "id": "rA99K5oJ0XV9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binayak-dhal/YoutTube-API-Data-Integration-Data-Lake-Creation/blob/main/Category_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "id": "view-in-github"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cac31077-4b66-4310-8851-2ac5d75721a1",
      "metadata": {
        "tags": [],
        "id": "cac31077-4b66-4310-8851-2ac5d75721a1"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow.keras\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import re,string,unicodedata\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "import gc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "ppW4ZAZe0hkV",
        "outputId": "6d45e8e3-4516-40a4-b30a-fe17f917993a"
      },
      "id": "ppW4ZAZe0hkV",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.28.35-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.32.0,>=1.31.35 (from boto3)\n",
            "  Downloading botocore-1.31.35-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3)\n",
            "  Downloading s3transfer-0.6.2-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.35->boto3) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4 (from botocore<1.32.0,>=1.31.35->boto3)\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.35->boto3) (1.16.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "Successfully installed boto3-1.28.35 botocore-1.31.35 jmespath-1.0.1 s3transfer-0.6.2 urllib3-1.26.16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "85cc0df8-5180-4506-a4d0-7e202c0d8135",
      "metadata": {
        "tags": [],
        "id": "85cc0df8-5180-4506-a4d0-7e202c0d8135"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import boto3\n",
        "\n",
        "# Set your AWS credentials\n",
        "aws_access_key_id = 'AKIAWIEAAEJF2JOVU4EE'\n",
        "aws_secret_access_key = 'Bc3GRxgYc3dIoO71WlMFLXKVVDdR/H8Fhv0q1Fo9'\n",
        "\n",
        "# Initialize the S3 client\n",
        "s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are using pandas for data manipulation and boto3 for interacting with aws services.>\n",
        "\n",
        "*  then we set the aws credentials\n",
        "*  and initialize the S3 client with the credentials\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vE99wYYW0nXt"
      },
      "id": "vE99wYYW0nXt"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "738cf39a-2f39-439e-8631-8daeb8d34167",
      "metadata": {
        "tags": [],
        "id": "738cf39a-2f39-439e-8631-8daeb8d34167"
      },
      "outputs": [],
      "source": [
        "bucket_name = 'di-yiutube-cleansed-bucket'\n",
        "csv_file_path = 'combined_data.csv'\n",
        "\n",
        "# Get the S3 object using the StreamingBody\n",
        "s3_object = s3.get_object(Bucket=bucket_name, Key=csv_file_path)\n",
        "\n",
        "# Get the StreamingBody from the S3 object response\n",
        "streaming_body = s3_object['Body']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are performing this step to extract the csv file from s3 bucket using boto3.\n",
        "\n",
        "*   using s3.get_object() to get the file from s3 where bucket is the name of s3 and key is path of csv file\n",
        "*   s3_object is used to get the output csv file in dictionary format.\n",
        "\n",
        "*   streaming_body is used to read the content of the file from S3 in a streaming manner and useful for handling large files efficiently without loading the entire file into memory."
      ],
      "metadata": {
        "id": "75nUsIN30q7q"
      },
      "id": "75nUsIN30q7q"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "60ae2cfb-0a7a-41a8-8a4e-61516b9b174b",
      "metadata": {
        "id": "60ae2cfb-0a7a-41a8-8a4e-61516b9b174b"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(streaming_body)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reading csv file through pandas"
      ],
      "metadata": {
        "id": "ESTrbG8s0u6L"
      },
      "id": "ESTrbG8s0u6L"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3d7b7d1f-0ff1-4675-ae3e-d44808abb247",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d7b7d1f-0ff1-4675-ae3e-d44808abb247",
        "outputId": "7926e7a9-d625-46b1-c3cb-891dc08d3dfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(667722, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "UATdgvF9Ceri",
        "outputId": "7e475fa1-a273-4112-dc28-0c1de10c17a0"
      },
      "id": "UATdgvF9Ceri",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      video_id                                              title  \\\n",
              "0  KX06ksuS6Xo  Diljit Dosanjh: CLASH (Official) Music Video |...   \n",
              "1  J78aPJ3VyNs  I left youtube for a month and THIS is what ha...   \n",
              "2  M9Pmf9AB4Mo  Apex Legends | Stories from the Outlands ‚Äì ‚ÄúTh...   \n",
              "3  3C66w5Z0ixs                 I ASKED HER TO BE MY GIRLFRIEND...   \n",
              "4  VIUo6yapDbc  Ultimate DIY Home Movie Theater for The LaBran...   \n",
              "\n",
              "            publishedAt                 channelId    channelTitle  categoryId  \\\n",
              "0  2020-08-11T07:30:02Z  UCZRdNleCgW-BGUJf-bbjzQg  Diljit Dosanjh          10   \n",
              "1  2020-08-11T16:34:06Z  UCYzPXprvl5Y-Sf0g4vX-m6g   jacksepticeye          24   \n",
              "2  2020-08-11T17:00:10Z  UC0ZV6M2THA81QT9hrVWJG3A    Apex Legends          20   \n",
              "3  2020-08-11T19:20:14Z  UCvtRTOMP2TqYqu51xNrqAzg        Brawadis          22   \n",
              "4  2020-08-11T15:10:05Z  UCDVPcEbVLQgLZX0Rt6jo34A        Mr. Kate          26   \n",
              "\n",
              "          trending_date                                               tags  \\\n",
              "0  2020-08-12T00:00:00Z  clash diljit dosanjh|diljit dosanjh|diljit dos...   \n",
              "1  2020-08-12T00:00:00Z  jacksepticeye|funny|funny meme|memes|jacksepti...   \n",
              "2  2020-08-12T00:00:00Z  Apex Legends|Apex Legends characters|new Apex ...   \n",
              "3  2020-08-12T00:00:00Z  brawadis|prank|basketball|skits|ghost|funny vi...   \n",
              "4  2020-08-12T00:00:00Z  The LaBrant Family|DIY|Interior Design|Makeove...   \n",
              "\n",
              "   view_count   likes  dislikes  comment_count  \\\n",
              "0     9140911  296541      6180          30059   \n",
              "1     2038853  353797      2628          40222   \n",
              "2     2381688  146740      2794          16549   \n",
              "3     1514614  156914      5857          35331   \n",
              "4     1123889   45803       964           2198   \n",
              "\n",
              "                                   thumbnail_link  comments_disabled  \\\n",
              "0  https://i.ytimg.com/vi/KX06ksuS6Xo/default.jpg              False   \n",
              "1  https://i.ytimg.com/vi/J78aPJ3VyNs/default.jpg              False   \n",
              "2  https://i.ytimg.com/vi/M9Pmf9AB4Mo/default.jpg              False   \n",
              "3  https://i.ytimg.com/vi/3C66w5Z0ixs/default.jpg              False   \n",
              "4  https://i.ytimg.com/vi/VIUo6yapDbc/default.jpg              False   \n",
              "\n",
              "   ratings_disabled                                        description  \n",
              "0             False  CLASH official music video performed by DILJIT...  \n",
              "1             False  I left youtube for a month and this is what ha...  \n",
              "2             False  While running her own modding shop, Ramya Pare...  \n",
              "3             False  SUBSCRIBE to BRAWADIS ‚ñ∂ http://bit.ly/Subscrib...  \n",
              "4             False  Transforming The LaBrant Family's empty white ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4d0bb04-2990-4eb8-bd1b-d3bcdc0166b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_id</th>\n",
              "      <th>title</th>\n",
              "      <th>publishedAt</th>\n",
              "      <th>channelId</th>\n",
              "      <th>channelTitle</th>\n",
              "      <th>categoryId</th>\n",
              "      <th>trending_date</th>\n",
              "      <th>tags</th>\n",
              "      <th>view_count</th>\n",
              "      <th>likes</th>\n",
              "      <th>dislikes</th>\n",
              "      <th>comment_count</th>\n",
              "      <th>thumbnail_link</th>\n",
              "      <th>comments_disabled</th>\n",
              "      <th>ratings_disabled</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KX06ksuS6Xo</td>\n",
              "      <td>Diljit Dosanjh: CLASH (Official) Music Video |...</td>\n",
              "      <td>2020-08-11T07:30:02Z</td>\n",
              "      <td>UCZRdNleCgW-BGUJf-bbjzQg</td>\n",
              "      <td>Diljit Dosanjh</td>\n",
              "      <td>10</td>\n",
              "      <td>2020-08-12T00:00:00Z</td>\n",
              "      <td>clash diljit dosanjh|diljit dosanjh|diljit dos...</td>\n",
              "      <td>9140911</td>\n",
              "      <td>296541</td>\n",
              "      <td>6180</td>\n",
              "      <td>30059</td>\n",
              "      <td>https://i.ytimg.com/vi/KX06ksuS6Xo/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>CLASH official music video performed by DILJIT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>J78aPJ3VyNs</td>\n",
              "      <td>I left youtube for a month and THIS is what ha...</td>\n",
              "      <td>2020-08-11T16:34:06Z</td>\n",
              "      <td>UCYzPXprvl5Y-Sf0g4vX-m6g</td>\n",
              "      <td>jacksepticeye</td>\n",
              "      <td>24</td>\n",
              "      <td>2020-08-12T00:00:00Z</td>\n",
              "      <td>jacksepticeye|funny|funny meme|memes|jacksepti...</td>\n",
              "      <td>2038853</td>\n",
              "      <td>353797</td>\n",
              "      <td>2628</td>\n",
              "      <td>40222</td>\n",
              "      <td>https://i.ytimg.com/vi/J78aPJ3VyNs/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>I left youtube for a month and this is what ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M9Pmf9AB4Mo</td>\n",
              "      <td>Apex Legends | Stories from the Outlands ‚Äì ‚ÄúTh...</td>\n",
              "      <td>2020-08-11T17:00:10Z</td>\n",
              "      <td>UC0ZV6M2THA81QT9hrVWJG3A</td>\n",
              "      <td>Apex Legends</td>\n",
              "      <td>20</td>\n",
              "      <td>2020-08-12T00:00:00Z</td>\n",
              "      <td>Apex Legends|Apex Legends characters|new Apex ...</td>\n",
              "      <td>2381688</td>\n",
              "      <td>146740</td>\n",
              "      <td>2794</td>\n",
              "      <td>16549</td>\n",
              "      <td>https://i.ytimg.com/vi/M9Pmf9AB4Mo/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>While running her own modding shop, Ramya Pare...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3C66w5Z0ixs</td>\n",
              "      <td>I ASKED HER TO BE MY GIRLFRIEND...</td>\n",
              "      <td>2020-08-11T19:20:14Z</td>\n",
              "      <td>UCvtRTOMP2TqYqu51xNrqAzg</td>\n",
              "      <td>Brawadis</td>\n",
              "      <td>22</td>\n",
              "      <td>2020-08-12T00:00:00Z</td>\n",
              "      <td>brawadis|prank|basketball|skits|ghost|funny vi...</td>\n",
              "      <td>1514614</td>\n",
              "      <td>156914</td>\n",
              "      <td>5857</td>\n",
              "      <td>35331</td>\n",
              "      <td>https://i.ytimg.com/vi/3C66w5Z0ixs/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>SUBSCRIBE to BRAWADIS ‚ñ∂ http://bit.ly/Subscrib...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>VIUo6yapDbc</td>\n",
              "      <td>Ultimate DIY Home Movie Theater for The LaBran...</td>\n",
              "      <td>2020-08-11T15:10:05Z</td>\n",
              "      <td>UCDVPcEbVLQgLZX0Rt6jo34A</td>\n",
              "      <td>Mr. Kate</td>\n",
              "      <td>26</td>\n",
              "      <td>2020-08-12T00:00:00Z</td>\n",
              "      <td>The LaBrant Family|DIY|Interior Design|Makeove...</td>\n",
              "      <td>1123889</td>\n",
              "      <td>45803</td>\n",
              "      <td>964</td>\n",
              "      <td>2198</td>\n",
              "      <td>https://i.ytimg.com/vi/VIUo6yapDbc/default.jpg</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Transforming The LaBrant Family's empty white ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4d0bb04-2990-4eb8-bd1b-d3bcdc0166b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a4d0bb04-2990-4eb8-bd1b-d3bcdc0166b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a4d0bb04-2990-4eb8-bd1b-d3bcdc0166b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-543be89a-1010-49b7-b6bc-fa73c281c039\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-543be89a-1010-49b7-b6bc-fa73c281c039')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-543be89a-1010-49b7-b6bc-fa73c281c039 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "70b5410d-8693-421d-a309-13e75b4a5686",
      "metadata": {
        "tags": [],
        "id": "70b5410d-8693-421d-a309-13e75b4a5686"
      },
      "outputs": [],
      "source": [
        "#df.rename(columns={'title_y': 'title'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "96325dd5-b768-4c9d-ae80-1dd70f40c974",
      "metadata": {
        "id": "96325dd5-b768-4c9d-ae80-1dd70f40c974"
      },
      "outputs": [],
      "source": [
        "#df.rename(columns={'title_x': 'category_name'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2192f643-06ee-41af-89d7-95831da35f39",
      "metadata": {
        "tags": [],
        "id": "2192f643-06ee-41af-89d7-95831da35f39"
      },
      "outputs": [],
      "source": [
        "#df.rename(columns={'category_id': 'categoryId'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "51f33dd4-3445-4577-8f9c-1a39bc6ae62e",
      "metadata": {
        "tags": [],
        "id": "51f33dd4-3445-4577-8f9c-1a39bc6ae62e"
      },
      "outputs": [],
      "source": [
        "#df.rename(columns={'views': 'view_count'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "de01c945-9bbf-4381-a147-62913dacf7aa",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de01c945-9bbf-4381-a147-62913dacf7aa",
        "outputId": "ebcc0667-31fa-4065-c696-e155b97f6745"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "video_id             object\n",
              "title                object\n",
              "publishedAt          object\n",
              "channelId            object\n",
              "channelTitle         object\n",
              "categoryId            int64\n",
              "trending_date        object\n",
              "tags                 object\n",
              "view_count            int64\n",
              "likes                 int64\n",
              "dislikes              int64\n",
              "comment_count         int64\n",
              "thumbnail_link       object\n",
              "comments_disabled      bool\n",
              "ratings_disabled       bool\n",
              "description          object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "77eb97b8-4683-4c7c-b0eb-8c342af6e2dd",
      "metadata": {
        "tags": [],
        "id": "77eb97b8-4683-4c7c-b0eb-8c342af6e2dd"
      },
      "outputs": [],
      "source": [
        "# Only these columns were selected because we have to predict category from the title given by the youtuber\n",
        "columns=['title','categoryId','view_count']\n",
        "main_data=df[columns].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are selecting few columns that are related to category from title and creating a copy as main_data to prevent any changes into original data"
      ],
      "metadata": {
        "id": "1DjPBPbk1025"
      },
      "id": "1DjPBPbk1025"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "eec5f5b4-18b6-4307-8f51-56f24c149db2",
      "metadata": {
        "tags": [],
        "id": "eec5f5b4-18b6-4307-8f51-56f24c149db2"
      },
      "outputs": [],
      "source": [
        "def count_words(main_data):\n",
        "\n",
        "    word_counter = 0\n",
        "\n",
        "    for texts in main_data[\"title\"]:\n",
        "        for words in texts:\n",
        "            word_counter = word_counter + 1\n",
        "\n",
        "    return word_counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "function takes a DataFrame with a \"title\" column as input, and it counts the total number of characters and total number of words in the \"title\"."
      ],
      "metadata": {
        "id": "TSQ0K2F814NG"
      },
      "id": "TSQ0K2F814NG"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5f0ba4ac-aa9d-4639-b845-e3fc51caa802",
      "metadata": {
        "tags": [],
        "id": "5f0ba4ac-aa9d-4639-b845-e3fc51caa802"
      },
      "outputs": [],
      "source": [
        "before_data_cleaning = count_words(main_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5b5fe6c8-9d07-49f3-8767-68fc465876b2",
      "metadata": {
        "tags": [],
        "id": "5b5fe6c8-9d07-49f3-8767-68fc465876b2"
      },
      "outputs": [],
      "source": [
        "contraction_mapping = {\n",
        "    \"Trump's\" : 'trump is',\"'cause\": 'because',',cause': 'because',';cause': 'because',\"ain't\": 'am not','ain,t': 'am not',\n",
        "    'ain;t': 'am not','ain¬¥t': 'am not','ain‚Äôt': 'am not',\"aren't\": 'are not',\n",
        "    'aren,t': 'are not','aren;t': 'are not','aren¬¥t': 'are not','aren‚Äôt': 'are not',\"can't\": 'cannot',\"can't've\": 'cannot have','can,t': 'cannot','can,t,ve': 'cannot have',\n",
        "    'can;t': 'cannot','can;t;ve': 'cannot have',\n",
        "    'can¬¥t': 'cannot','can¬¥t¬¥ve': 'cannot have','can‚Äôt': 'cannot','can‚Äôt‚Äôve': 'cannot have',\n",
        "    \"could've\": 'could have','could,ve': 'could have','could;ve': 'could have',\"couldn't\": 'could not',\"couldn't've\": 'could not have','couldn,t': 'could not','couldn,t,ve': 'could not have','couldn;t': 'could not',\n",
        "    'couldn;t;ve': 'could not have','couldn¬¥t': 'could not',\n",
        "    'couldn¬¥t¬¥ve': 'could not have','couldn‚Äôt': 'could not','couldn‚Äôt‚Äôve': 'could not have','could¬¥ve': 'could have',\n",
        "    'could‚Äôve': 'could have',\"didn't\": 'did not','didn,t': 'did not','didn;t': 'did not','didn¬¥t': 'did not',\n",
        "    'didn‚Äôt': 'did not',\"doesn't\": 'does not','doesn,t': 'does not','doesn;t': 'does not','doesn¬¥t': 'does not',\n",
        "    'doesn‚Äôt': 'does not',\"don't\": 'do not','don,t': 'do not','don;t': 'do not','don¬¥t': 'do not','don‚Äôt': 'do not',\n",
        "    \"hadn't\": 'had not',\"hadn't've\": 'had not have','hadn,t': 'had not','hadn,t,ve': 'had not have','hadn;t': 'had not',\n",
        "    'hadn;t;ve': 'had not have','hadn¬¥t': 'had not','hadn¬¥t¬¥ve': 'had not have','hadn‚Äôt': 'had not','hadn‚Äôt‚Äôve': 'had not have',\"hasn't\": 'has not','hasn,t': 'has not','hasn;t': 'has not','hasn¬¥t': 'has not','hasn‚Äôt': 'has not',\n",
        "    \"haven't\": 'have not','haven,t': 'have not','haven;t': 'have not','haven¬¥t': 'have not','haven‚Äôt': 'have not',\"he'd\": 'he would',\n",
        "    \"he'd've\": 'he would have',\"he'll\": 'he will',\n",
        "    \"he's\": 'he is','he,d': 'he would','he,d,ve': 'he would have','he,ll': 'he will','he,s': 'he is','he;d': 'he would',\n",
        "    'he;d;ve': 'he would have','he;ll': 'he will','he;s': 'he is','he¬¥d': 'he would','he¬¥d¬¥ve': 'he would have','he¬¥ll': 'he will',\n",
        "    'he¬¥s': 'he is','he‚Äôd': 'he would','he‚Äôd‚Äôve': 'he would have','he‚Äôll': 'he will','he‚Äôs': 'he is',\"how'd\": 'how did',\"how'll\": 'how will',\n",
        "    \"how's\": 'how is','how,d': 'how did','how,ll': 'how will','how,s': 'how is','how;d': 'how did','how;ll': 'how will',\n",
        "    'how;s': 'how is','how¬¥d': 'how did','how¬¥ll': 'how will','how¬¥s': 'how is','how‚Äôd': 'how did','how‚Äôll': 'how will',\n",
        "    'how‚Äôs': 'how is',\"i'd\": 'i would',\"i'll\": 'i will',\"i'm\": 'i am',\"i've\": 'i have','i,d': 'i would','i,ll': 'i will',\n",
        "    'i,m': 'i am','i,ve': 'i have','i;d': 'i would','i;ll': 'i will','i;m': 'i am','i;ve': 'i have',\"isn't\": 'is not',\n",
        "    'isn,t': 'is not','isn;t': 'is not','isn¬¥t': 'is not','isn‚Äôt': 'is not',\"it'd\": 'it would',\"it'll\": 'it will',\"It's\":'it is',\n",
        "    \"it's\": 'it is','it,d': 'it would','it,ll': 'it will','it,s': 'it is','it;d': 'it would','it;ll': 'it will','it;s': 'it is','it¬¥d': 'it would','it¬¥ll': 'it will','it¬¥s': 'it is',\n",
        "    'it‚Äôd': 'it would','it‚Äôll': 'it will','it‚Äôs': 'it is',\n",
        "    'i¬¥d': 'i would','i¬¥ll': 'i will','i¬¥m': 'i am','i¬¥ve': 'i have','i‚Äôd': 'i would','i‚Äôll': 'i will','i‚Äôm': 'i am',\n",
        "    'i‚Äôve': 'i have',\"let's\": 'let us','let,s': 'let us','let;s': 'let us','let¬¥s': 'let us',\n",
        "    'let‚Äôs': 'let us',\"ma'am\": 'madam','ma,am': 'madam','ma;am': 'madam',\"mayn't\": 'may not','mayn,t': 'may not','mayn;t': 'may not',\n",
        "    'mayn¬¥t': 'may not','mayn‚Äôt': 'may not','ma¬¥am': 'madam','ma‚Äôam': 'madam',\"might've\": 'might have','might,ve': 'might have','might;ve': 'might have',\"mightn't\": 'might not','mightn,t': 'might not','mightn;t': 'might not','mightn¬¥t': 'might not',\n",
        "    'mightn‚Äôt': 'might not','might¬¥ve': 'might have','might‚Äôve': 'might have',\"must've\": 'must have','must,ve': 'must have','must;ve': 'must have',\n",
        "    \"mustn't\": 'must not','mustn,t': 'must not','mustn;t': 'must not','mustn¬¥t': 'must not','mustn‚Äôt': 'must not','must¬¥ve': 'must have',\n",
        "    'must‚Äôve': 'must have',\"needn't\": 'need not','needn,t': 'need not','needn;t': 'need not','needn¬¥t': 'need not','needn‚Äôt': 'need not',\"oughtn't\": 'ought not','oughtn,t': 'ought not','oughtn;t': 'ought not',\n",
        "    'oughtn¬¥t': 'ought not','oughtn‚Äôt': 'ought not',\"sha'n't\": 'shall not','sha,n,t': 'shall not','sha;n;t': 'shall not',\"shan't\": 'shall not',\n",
        "    'shan,t': 'shall not','shan;t': 'shall not','shan¬¥t': 'shall not','shan‚Äôt': 'shall not','sha¬¥n¬¥t': 'shall not','sha‚Äôn‚Äôt': 'shall not',\n",
        "    \"she'd\": 'she would',\"she'll\": 'she will',\"she's\": 'she is','she,d': 'she would','she,ll': 'she will',\n",
        "    'she,s': 'she is','she;d': 'she would','she;ll': 'she will','she;s': 'she is','she¬¥d': 'she would','she¬¥ll': 'she will',\n",
        "    'she¬¥s': 'she is','she‚Äôd': 'she would','she‚Äôll': 'she will','she‚Äôs': 'she is',\"should've\": 'should have','should,ve': 'should have','should;ve': 'should have',\n",
        "    \"shouldn't\": 'should not','shouldn,t': 'should not','shouldn;t': 'should not','shouldn¬¥t': 'should not','shouldn‚Äôt': 'should not','should¬¥ve': 'should have',\n",
        "    'should‚Äôve': 'should have',\"that'd\": 'that would',\"that's\": 'that is','that,d': 'that would','that,s': 'that is','that;d': 'that would',\n",
        "    'that;s': 'that is','that¬¥d': 'that would','that¬¥s': 'that is','that‚Äôd': 'that would','that‚Äôs': 'that is',\"there'd\": 'there had',\n",
        "    \"there's\": 'there is','there,d': 'there had','there,s': 'there is','there;d': 'there had','there;s': 'there is',\n",
        "    'there¬¥d': 'there had','there¬¥s': 'there is','there‚Äôd': 'there had','there‚Äôs': 'there is',\n",
        "    \"they'd\": 'they would',\"they'll\": 'they will',\"they're\": 'they are',\"they've\": 'they have',\n",
        "    'they,d': 'they would','they,ll': 'they will','they,re': 'they are','they,ve': 'they have','they;d': 'they would','they;ll': 'they will','they;re': 'they are',\n",
        "    'they;ve': 'they have','they¬¥d': 'they would','they¬¥ll': 'they will','they¬¥re': 'they are','they¬¥ve': 'they have','they‚Äôd': 'they would','they‚Äôll': 'they will',\n",
        "    'they‚Äôre': 'they are','they‚Äôve': 'they have',\"wasn't\": 'was not','wasn,t': 'was not','wasn;t': 'was not','wasn¬¥t': 'was not',\n",
        "    'wasn‚Äôt': 'was not',\"we'd\": 'we would',\"we'll\": 'we will',\"we're\": 'we are',\"we've\": 'we have','we,d': 'we would','we,ll': 'we will',\n",
        "    'we,re': 'we are','we,ve': 'we have','we;d': 'we would','we;ll': 'we will','we;re': 'we are','we;ve': 'we have',\n",
        "    \"weren't\": 'were not','weren,t': 'were not','weren;t': 'were not','weren¬¥t': 'were not','weren‚Äôt': 'were not','we¬¥d': 'we would','we¬¥ll': 'we will',\n",
        "    'we¬¥re': 'we are','we¬¥ve': 'we have','we‚Äôd': 'we would','we‚Äôll': 'we will','we‚Äôre': 'we are','we‚Äôve': 'we have',\"what'll\": 'what will',\"what're\": 'what are',\"what's\": 'what is',\n",
        "    \"what've\": 'what have','what,ll': 'what will','what,re': 'what are','what,s': 'what is','what,ve': 'what have','what;ll': 'what will','what;re': 'what are',\n",
        "    'what;s': 'what is','what;ve': 'what have','what¬¥ll': 'what will',\n",
        "    'what¬¥re': 'what are','what¬¥s': 'what is','what¬¥ve': 'what have','what‚Äôll': 'what will','what‚Äôre': 'what are','what‚Äôs': 'what is',\n",
        "    'what‚Äôve': 'what have',\"where'd\": 'where did',\"where's\": 'where is','where,d': 'where did','where,s': 'where is','where;d': 'where did',\n",
        "    'where;s': 'where is','where¬¥d': 'where did','where¬¥s': 'where is','where‚Äôd': 'where did','where‚Äôs': 'where is',\n",
        "    \"who'll\": 'who will',\"who's\": 'who is','who,ll': 'who will','who,s': 'who is','who;ll': 'who will','who;s': 'who is',\n",
        "    'who¬¥ll': 'who will','who¬¥s': 'who is','who‚Äôll': 'who will','who‚Äôs': 'who is',\"won't\": 'will not','won,t': 'will not','won;t': 'will not',\n",
        "    'won¬¥t': 'will not','won‚Äôt': 'will not',\"wouldn't\": 'would not','wouldn,t': 'would not','wouldn;t': 'would not','wouldn¬¥t': 'would not',\n",
        "    'wouldn‚Äôt': 'would not',\"you'd\": 'you would',\"you'll\": 'you will',\"you're\": 'you are','you,d': 'you would','you,ll': 'you will',\n",
        "    'you,re': 'you are','you;d': 'you would','you;ll': 'you will',\n",
        "    'you;re': 'you are','you¬¥d': 'you would','you¬¥ll': 'you will','you¬¥re': 'you are','you‚Äôd': 'you would','you‚Äôll': 'you will','you‚Äôre': 'you are',\n",
        "    '¬¥cause': 'because','‚Äôcause': 'because',\"you've\": \"you have\",\"could'nt\": 'could not',\n",
        "    \"havn't\": 'have not',\"here‚Äôs\": \"here is\",'i\"\"m': 'i am',\"i'am\": 'i am',\"i'l\": \"i will\",\"i'v\": 'i have',\"wan't\": 'want',\"was'nt\": \"was not\",\"who'd\": \"who would\",\n",
        "    \"who're\": \"who are\",\"who've\": \"who have\",\"why'd\": \"why would\",\"would've\": \"would have\",\"y'all\": \"you all\",\"y'know\": \"you know\",\"you.i\": \"you i\",\n",
        "    \"your'e\": \"you are\",\"arn't\": \"are not\",\"agains't\": \"against\",\"c'mon\": \"common\",\"doens't\": \"does not\",'don\"\"t': \"do not\",\"dosen't\": \"does not\",\n",
        "    \"dosn't\": \"does not\",\"shoudn't\": \"should not\",\"that'll\": \"that will\",\"there'll\": \"there will\",\"there're\": \"there are\",\n",
        "    \"this'll\": \"this all\",\"u're\": \"you are\", \"ya'll\": \"you all\",\"you'r\": \"you are\",\"you‚Äôve\": \"you have\",\"d'int\": \"did not\",\"did'nt\": \"did not\",\"din't\": \"did not\",\"dont't\": \"do not\",\"gov't\": \"government\",\n",
        "    \"i'ma\": \"i am\",\"is'nt\": \"is not\",\"‚ÄòI\":'I',\n",
        "    '·¥Ä…¥·¥Ö':'and','·¥õ ú·¥á':'the',' ú·¥è·¥ç·¥á':'home','·¥ú·¥ò':'up',' ô è':'by','·¥Ä·¥õ':'at','‚Ä¶and':'and','civilbeat':'civil beat',\\\n",
        "    'TrumpCare':'Trump care','Trumpcare':'Trump care', 'OBAMAcare':'Obama care','·¥Ñ ú·¥á·¥Ñ·¥ã':'check','“ì·¥è Ä':'for','·¥õ ú…™s':'this','·¥Ñ·¥è·¥ç·¥ò·¥ú·¥õ·¥á Ä':'computer',\\\n",
        "    '·¥ç·¥è…¥·¥õ ú':'month','·¥°·¥è Ä·¥ã…™…¥…¢':'working','·¥ä·¥è ô':'job','“ì Ä·¥è·¥ç':'from','S·¥õ·¥Ä Ä·¥õ':'start','gubmit':'submit','CO‚ÇÇ':'carbon dioxide','“ì…™ Äs·¥õ':'first',\\\n",
        "    '·¥á…¥·¥Ö':'end','·¥Ñ·¥Ä…¥':'can',' ú·¥Ä·¥†·¥á':'have','·¥õ·¥è':'to',' ü…™…¥·¥ã':'link','·¥è“ì':'of',' ú·¥è·¥ú Ä ü è':'hourly','·¥°·¥á·¥á·¥ã':'week','·¥á…¥·¥Ö':'end','·¥áx·¥õ Ä·¥Ä':'extra',\\\n",
        "    'G Ä·¥á·¥Ä·¥õ':'great','s·¥õ·¥ú·¥Ö·¥á…¥·¥õs':'student','s·¥õ·¥Ä è':'stay','·¥ç·¥è·¥çs':'mother','·¥è Ä':'or','·¥Ä…¥ è·¥è…¥·¥á':'anyone','…¥·¥á·¥á·¥Ö…™…¥…¢':'needing','·¥Ä…¥':'an','…™…¥·¥Ñ·¥è·¥ç·¥á':'income',\\\n",
        "    ' Ä·¥á ü…™·¥Ä ô ü·¥á':'reliable','“ì…™ Äs·¥õ':'first',' è·¥è·¥ú Ä':'your','s…™…¢…¥…™…¥…¢':'signing',' ô·¥è·¥õ·¥õ·¥è·¥ç':'bottom','“ì·¥è ü ü·¥è·¥°…™…¥…¢':'following','M·¥Ä·¥ã·¥á':'make',\\\n",
        "    '·¥Ñ·¥è…¥…¥·¥á·¥Ñ·¥õ…™·¥è…¥':'connection','…™…¥·¥õ·¥á Ä…¥·¥á·¥õ':'internet','financialpost':'financial post', ' úa·¥†·¥á':' have ', '·¥Ña…¥':' can ', 'Ma·¥ã·¥á':' make ', ' Ä·¥á ü…™a ô ü·¥á':' reliable ', '…¥·¥á·¥á·¥Ö':' need ',\n",
        "    '·¥è…¥ ü è':' only ', '·¥áx·¥õ Äa':' extra ', 'a…¥':' an ', 'a…¥ è·¥è…¥·¥á':' anyone ', 's·¥õa è':' stay ', 'S·¥õa Ä·¥õ':' start', 'SHOPO':'shop',\n",
        "    }\n",
        "mispell_dict = {'SB91':'senate bill','tRump':'trump','utmterm':'utm term','FakeNews':'fake news','G Ä·¥áat':'great',' ô·¥è·¥õto·¥ç':'bottom','washingtontimes':'washington times','garycrum':'gary crum','htmlutmterm':'html utm term','RangerMC':'car','TFWs':'tuition fee waiver','SJWs':'social justice warrior','Koncerned':'concerned','Vinis':'vinys','Y·¥è·¥ú':'you','Trumpsters':'trump','Trumpian':'trump','bigly':'big league','Trumpism':'trump','Yoyou':'you','Auwe':'wonder','Drumpf':'trump','utmterm':'utm term','Brexit':'british exit','utilitas':'utilities','·¥Ä':'a', 'üòâ':'wink','üòÇ':'joy','üòÄ':'stuck out tongue', 'theguardian':'the guardian','deplorables':'deplorable', 'theglobeandmail':'the globe and mail', 'justiciaries': 'justiciary','creditdation': 'Accreditation','doctrne':'doctrine','fentayal': 'fentanyl','designation-': 'designation','CONartist' : 'con-artist','Mutilitated' : 'Mutilated','Obumblers': 'bumblers','negotiatiations': 'negotiations','dood-': 'dood','irakis' : 'iraki','cooerate': 'cooperate','COx':'cox','racistcomments':'racist comments','envirnmetalists': 'environmentalists',}\n",
        "\n",
        "special_punc_mappings = {\"‚Äî\": \"-\", \"‚Äì\": \"-\", \"_\": \"-\", '‚Äù': '\"', \"‚Ä≥\": '\"', '‚Äú': '\"', '‚Ä¢': '.', '‚àí': '-',\n",
        "                         \"‚Äô\": \"'\", \"‚Äò\": \"'\", \"¬¥\": \"'\", \"`\": \"'\", '\\u200b': ' ', '\\xa0': ' ','ÿå':'','‚Äû':'',\n",
        "                         '‚Ä¶': ' ... ', '\\ufeff': ''}\n",
        "\n",
        "spaces = ['\\u200b', '\\u200e', '\\u202a', '\\u202c', '\\ufeff', '\\uf0d8', '\\u2061', '\\x10', '\\x7f', '\\x9d', '\\xad', '\\xa0']\n",
        "\n",
        "extra_punct = [\n",
        "    ',', '.', '\"', ':', ')', '(', '!', '?', '|', ';', \"'\", '$', '&',\n",
        "    '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '‚Ä¢',  '~', '@', '¬£',\n",
        "    '¬∑', '_', '{', '}', '¬©', '^', '¬Æ', '`',  '<', '‚Üí', '¬∞', '‚Ç¨', '‚Ñ¢', '‚Ä∫',\n",
        "    '‚ô•', '‚Üê', '√ó', '¬ß', '‚Ä≥', '‚Ä≤', '√Ç', '‚ñà', '¬Ω', '√†', '‚Ä¶', '‚Äú', '‚òÖ', '‚Äù',\n",
        "    '‚Äì', '‚óè', '√¢', '‚ñ∫', '‚àí', '¬¢', '¬≤', '¬¨', '‚ñë', '¬∂', '‚Üë', '¬±', '¬ø', '‚ñæ',\n",
        "    '‚ïê', '¬¶', '‚ïë', '‚Äï', '¬•', '‚ñì', '‚Äî', '‚Äπ', '‚îÄ', '‚ñí', 'Ôºö', '¬º', '‚äï', '‚ñº',\n",
        "    '‚ñ™', '‚Ä†', '‚ñ†', '‚Äô', '‚ñÄ', '¬®', '‚ñÑ', '‚ô´', '‚òÜ', '√©', '¬Ø', '‚ô¶', '¬§', '‚ñ≤',\n",
        "    '√®', '¬∏', '¬æ', '√É', '‚ãÖ', '‚Äò', '‚àû', '‚àô', 'Ôºâ', '‚Üì', '„ÄÅ', '‚îÇ', 'Ôºà', '¬ª',\n",
        "    'Ôºå', '‚ô™', '‚ï©', '‚ïö', '¬≥', '„Éª', '‚ï¶', '‚ï£', '‚ïî', '‚ïó', '‚ñ¨', '‚ù§', '√Ø', '√ò',\n",
        "    '¬π', '‚â§', '‚Ä°', '‚àö', '¬´', '¬ª', '¬¥', '¬∫', '¬æ', '¬°', '¬ß', '¬£', '‚Ç§']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "58eaba52-43d7-4c4d-bc96-b42f856f9678",
      "metadata": {
        "tags": [],
        "id": "58eaba52-43d7-4c4d-bc96-b42f856f9678"
      },
      "outputs": [],
      "source": [
        "def remove_space(text):\n",
        "    \"\"\"\n",
        "    remove extra spaces and ending space if any\n",
        "    \"\"\"\n",
        "    for space in spaces:\n",
        "        text = text.replace(space, ' ')\n",
        "    text = text.strip()\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    return text\n",
        "def clean_special_punctuations(text):\n",
        "    for punc in special_punc_mappings:\n",
        "        if punc in text:\n",
        "            text = text.replace(punc, special_punc_mappings[punc])\n",
        "    # remove_diacritics don¬¥t' ->  'don t'\n",
        "    #text = remove_diacritics(text)\n",
        "    return text\n",
        "def clean_number(text):\n",
        "    text = re.sub(r'(\\d+)([a-zA-Z])', '\\g<1> \\g<2>', text)\n",
        "    text = re.sub(r'(\\d+) (th|st|nd|rd) ', '\\g<1>\\g<2> ', text)\n",
        "    text = re.sub(r'(\\d+),(\\d+)', '\\g<1>\\g<2>', text)\n",
        "    text = re.sub(r'(\\d+)(e)(\\d+)','\\g<1> \\g<3>', text)\n",
        "\n",
        "    return text\n",
        "def pre_clean_rare_words(text):\n",
        "    for rare_word in rare_words_mapping:\n",
        "        if rare_word in text:\n",
        "            text = text.replace(rare_word, rare_words_mapping[rare_word])\n",
        "\n",
        "    return text\n",
        "def clean_misspell(text):\n",
        "    for bad_word in mispell_dict:\n",
        "        if bad_word in text:\n",
        "            text = text.replace(bad_word, mispell_dict[bad_word])\n",
        "    return text\n",
        "\n",
        "import string\n",
        "regular_punct = list(string.punctuation)\n",
        "all_punct = list(set(regular_punct + extra_punct))\n",
        "# do not spacing - and .\n",
        "all_punct.remove('-')\n",
        "all_punct.remove('.')\n",
        "\n",
        "def spacing_punctuation(text):\n",
        "    \"\"\"\n",
        "    add space before and after punctuation and symbols\n",
        "    \"\"\"\n",
        "    for punc in all_punct:\n",
        "        if punc in text:\n",
        "            text = text.replace(punc, f' {punc} ')\n",
        "    return text\n",
        "def clean_repeat_words(text):\n",
        "\n",
        "    text = re.sub(r\"\\b(I|i)(I|i)+ng\\b\", \"ing\", text) #this one is causing few issues(fixed via monkey patching in other dicts for now), need to check it..\n",
        "    text = re.sub(r\"(-+|\\.+)\", \" \", text)\n",
        "    return text\n",
        "\n",
        "def correct_contraction(x, dic):\n",
        "    for word in dic.keys():\n",
        "        if word in x:\n",
        "            x = x.replace(word, dic[word])\n",
        "    return x\n",
        "\n",
        "def correct_spelling(x, dic):\n",
        "    for word in dic.keys():\n",
        "        if word in x:\n",
        "            x = x.replace(word, dic[word])\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "951f544a-2b1d-4ce4-81dd-ac5faf2b7616",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "951f544a-2b1d-4ce4-81dd-ac5faf2b7616",
        "outputId": "a93aa34e-a607-45f7-8c60-eea59e80186f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "def clean_text(text):\n",
        "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
        "    and remove words containing numbers.'''\n",
        "    text = str(text).lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+',\"\", text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = re.sub('\\'','', text)\n",
        "    text = re.sub(r'(\\d+)([a-zA-Z])', '\\g<1> \\g<2>', text)\n",
        "    text = re.sub(r'(\\d+) (th|st|nd|rd) ', '\\g<1>\\g<2> ', text)\n",
        "    text = re.sub(r'(\\d+),(\\d+)', '\\g<1>\\g<2>', text)\n",
        "    text = re.sub(r'(\\d+)(e)(\\d+)','\\g<1> \\g<3>', text)\n",
        "    text = ''.join([c for c in text if c not in punctuation])\n",
        "    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"\", text)\n",
        "    text = re.sub(r\"What's\", \"\", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"I'm\", \"I am\", text)\n",
        "    text = re.sub(r\" m \", \" am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\"60k\", \" 60000 \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e-mail\", \"email\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    text = re.sub(r\"quikly\", \"quickly\", text)\n",
        "    text = re.sub(r\" usa \", \" america \", text)\n",
        "    text = re.sub(r\" USA \", \" america \", text)\n",
        "    text = re.sub(r\" u s \", \" america \", text)\n",
        "    text = re.sub(r\" uk \", \" england \", text)\n",
        "    text = re.sub(r\" UK \", \" england \", text)\n",
        "    text = re.sub(r\"india\", \"india\", text)\n",
        "    text = re.sub(r\"switzerland\", \"switzerland\", text)\n",
        "    text = re.sub(r\"china\", \"china\", text)\n",
        "    text = re.sub(r\"chinese\", \"chinese\", text)\n",
        "    text = re.sub(r\"imrovement\", \"improvement\", text)\n",
        "    text = re.sub(r\"intially\", \"initially\", text)\n",
        "    text = re.sub(r\"quora\", \"quora\", text)\n",
        "    text = re.sub(r\" dms \", \"direct messages \", text)\n",
        "    text = re.sub(r\"demonitization\", \"demonetization\", text)\n",
        "    text = re.sub(r\"actived\", \"active\", text)\n",
        "    text = re.sub(r\"kms\", \" kilometers \", text)\n",
        "    text = re.sub(r\"KMs\", \" kilometers \", text)\n",
        "    text = re.sub(r\" cs \", \" computer science \", text)\n",
        "    text = re.sub(r\" upvotes \", \" up votes \", text)\n",
        "    text = re.sub(r\" iPhone \", \" phone \", text)\n",
        "    text = re.sub(r\"\\0rs \", \" rs \", text)\n",
        "    text = re.sub(r\"calender\", \"calendar\", text)\n",
        "    text = re.sub(r\"ios\", \"operating system\", text)\n",
        "    text = re.sub(r\"gps\", \"GPS\", text)\n",
        "    text = re.sub(r\"gst\", \"GST\", text)\n",
        "    text = re.sub(r\"programing\", \"programming\", text)\n",
        "    text = re.sub(r\"bestfriend\", \"best friend\", text)\n",
        "    text = re.sub(r\"dna\", \"DNA\", text)\n",
        "    text = re.sub(r\"III\", \"3\", text)\n",
        "    text = re.sub(r\"the US\", \"america\", text)\n",
        "    text = re.sub(r\"Astrology\", \"astrology\", text)\n",
        "    text = re.sub(r\"Method\", \"method\", text)\n",
        "    text = re.sub(r\"Find\", \"find\", text)\n",
        "    text = re.sub(r\"banglore\", \"Banglore\", text)\n",
        "    text = re.sub(r\" J K \", \" JK \", text)\n",
        "    text = re.sub(r\" (W|w)hat+(s)*[A|a]*(p)+ \", \" WhatsApp \", text)\n",
        "    text = re.sub(r\" (W|w)hat\\S \", \" What \", text)\n",
        "    text = re.sub(r\" \\S(W|w)hat \", \" What \", text)\n",
        "    text = re.sub(r\" (W|w)hy\\S \", \" Why \", text)\n",
        "    text = re.sub(r\" \\S(W|w)hy \", \" Why \", text)\n",
        "    text = re.sub(r\" (H|h)ow\\S \", \" How \", text)\n",
        "    text = re.sub(r\" \\S(H|h)ow \", \" How \", text)\n",
        "    text = re.sub(r\" (W|w)hich\\S \", \" Which \", text)\n",
        "    text = re.sub(r\" \\S(W|w)hich \", \" Which \", text)\n",
        "    text = re.sub(r\" (W|w)here\\S \", \" Where \", text)\n",
        "    text = re.sub(r\" \\S(W|w)here \", \" Where \", text)\n",
        "    text = text.replace(\"What sApp\", ' WhatsApp ')\n",
        "    text = remove_space(text)\n",
        "    text = re.sub(r\"minut\", \"Banglominutere\", text)\n",
        "    text = str(text).lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = re.sub('\\'','', text)\n",
        "    text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
        "\n",
        "\n",
        "    text = str(text).replace(' s ','').replace('‚Ä¶', ' ').replace('‚Äî','-').replace('‚Ä¢¬∞‚Ä¢¬∞‚Ä¢','') #should be broken down to regexs (lazy to do it haha)\n",
        "    for punct in \"/-'\":\n",
        "        if punct in text:\n",
        "            text = text.replace(punct, ' ')\n",
        "    for punct in '&':\n",
        "        if punct in text:\n",
        "            text = text.replace(punct, f' {punct} ')\n",
        "    for punct in '?!-,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~‚Äì‚Äî‚ú∞¬´¬ª¬ß‚úà‚û§‚Ä∫‚ò≠‚úî¬Ω‚ò∫√©√Ø√†üòèü§£üò¢üòÅüôÑüòÉüòÑüòäüòúüòéüòÜüíôüëçü§îüòÖüò°‚ñÄ‚ñÑ¬∑‚Äï‚ïê‚ñ∫‚ô•‚ñ¨' + '‚Äú‚Äù‚Äô':\n",
        "        #if we add . here then all the WEBPAGE LINKS WILL VANISH WE DON'T WANT THAT\n",
        "        if punct in text: #can be used a FE for emojis but here we are just removing them..\n",
        "            text = text.replace(punct, '')\n",
        "    for punct in '.‚Ä¢': #hence here it is\n",
        "        if punct in text:\n",
        "            text = text.replace(punct, f' ')\n",
        "\n",
        "    text = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f\\xad]', '', text)\n",
        "    text = re.sub(r'(\\d+)(e)(\\d+)',r'\\g<1> \\g<3>', text) #is a dup from above cell...\n",
        "    text = re.sub(r\"(-+|\\.+)\\s?\", \"  \", text)\n",
        "    text = re.sub(\"\\s\\s+\", \" \", text)\n",
        "    text = re.sub(r'·¥µ+', '', text)\n",
        "\n",
        "    text = re.sub(r'(can|by|been|and|are|for|it|TV|already|justhow|some|had|is|will|would|should|shall|must|can|his|here|there|them|these|their|has|have|the|be|that|not|was|he|just|they|who)(how)', '\\g<1> \\g<2>', text)\n",
        "    return text\n",
        "#main_data['title'] = main_data['title'].progress_apply(lambda x:clean_text(x))\n",
        "gc.collect()\n",
        "#main_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "category_data = [\n",
        "    (1, 'Film & Animation'),\n",
        "    (2, 'Autos & Vehicle'),\n",
        "    (10, 'Music'),\n",
        "    (15, 'Pets & Animals'),\n",
        "    (17, 'Sports'),\n",
        "    (19, 'Travel & Events'),\n",
        "    (20, 'Gaming'),\n",
        "    (22, 'People & Blogs'),\n",
        "    (23, 'Comedy'),\n",
        "    (24, 'Entertainment'),\n",
        "    (25, 'News & Politics'),\n",
        "    (26, 'Howto & Style'),\n",
        "    (27, 'Education'),\n",
        "    (28, 'Science & Technology'),\n",
        "    (30, 'Movies'),\n",
        "    (43, 'Shows'),\n",
        "    (29, 'Nonprofits & Activism')\n",
        "]\n",
        "\n",
        "# Create a dictionary to map category IDs to category names which are collected from the Json files attached in the data\n",
        "cat_dict = {category_id: category_name for category_id, category_name in category_data}\n",
        "\n"
      ],
      "metadata": {
        "id": "PEc0uART7pIr"
      },
      "id": "PEc0uART7pIr",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ce79adf-5937-4369-9acb-0daefbaa8a5d",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ce79adf-5937-4369-9acb-0daefbaa8a5d",
        "outputId": "ab24be39-4678-42b6-9e4d-7721985b6948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 336982/667722 [01:16<01:02, 5295.31it/s]"
          ]
        }
      ],
      "source": [
        "def preprocess(text):\n",
        "\n",
        "    text = remove_space(text)\n",
        "    text = clean_special_punctuations(text)\n",
        "    text = clean_number(text)\n",
        "    text = clean_misspell(text)\n",
        "    text = spacing_punctuation(text)\n",
        "\n",
        "    text = clean_repeat_words(text)\n",
        "    text = remove_space(text)\n",
        "    text = clean_text(text)\n",
        "    return text\n",
        "\n",
        "main_data['title'] = main_data['title'].progress_apply(lambda x:preprocess(x))\n",
        "gc.collect()\n",
        "main_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c52578bf-69fd-4130-9258-2e95e770d31d",
      "metadata": {
        "tags": [],
        "id": "c52578bf-69fd-4130-9258-2e95e770d31d"
      },
      "outputs": [],
      "source": [
        "after_data_cleaning_new = count_words(main_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1827a6e-e2ed-4723-80db-9d2afd973125",
      "metadata": {
        "tags": [],
        "id": "a1827a6e-e2ed-4723-80db-9d2afd973125"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecd4c730-dfb3-4371-a1fe-d7e40ce54938",
      "metadata": {
        "tags": [],
        "id": "ecd4c730-dfb3-4371-a1fe-d7e40ce54938"
      },
      "outputs": [],
      "source": [
        "porter_stemmer = PorterStemmer()\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lexicon_normalization(text):\n",
        "\n",
        "    # 1- Stemming\n",
        "    words_stem = porter_stemmer.stem(text)\n",
        "\n",
        "    #  Lemmatization\n",
        "    words_lem = wordnet_lemmatizer.lemmatize(words_stem)\n",
        "    return words_lem\n",
        "main_data['title']= main_data['title'].progress_apply(lambda x: lexicon_normalization(x))\n",
        "main_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e4ac7a6-193d-4c89-a40f-1922f37f167f",
      "metadata": {
        "tags": [],
        "id": "7e4ac7a6-193d-4c89-a40f-1922f37f167f"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "from collections import Counter\n",
        "def remove_stopword(text):\n",
        "    stop_words = stopwords.words('english')\n",
        "    #stopwords_dict = Counter(stop_words)\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "main_data['title']=main_data['title'].progress_apply(lambda x: remove_stopword(x))\n",
        "\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80c40b8c-1ee6-4472-8ce1-e5ffeb041c5d",
      "metadata": {
        "tags": [],
        "id": "80c40b8c-1ee6-4472-8ce1-e5ffeb041c5d"
      },
      "outputs": [],
      "source": [
        "after_cleaning_stopwords = count_words(main_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cf478f2-71cb-41fe-bde2-1ca3ce1a6eee",
      "metadata": {
        "tags": [],
        "id": "1cf478f2-71cb-41fe-bde2-1ca3ce1a6eee"
      },
      "outputs": [],
      "source": [
        "def tokenise(text):\n",
        "    words = word_tokenize(text)\n",
        "    return words\n",
        "\n",
        "def retokenise(word_list):\n",
        "    sentence = \"\"\n",
        "    for word in word_list:\n",
        "        sentence = sentence + \" \" + word\n",
        "    return sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94e6fe6d-102b-48dd-aed4-5f303e310bce",
      "metadata": {
        "tags": [],
        "id": "94e6fe6d-102b-48dd-aed4-5f303e310bce"
      },
      "outputs": [],
      "source": [
        "blacklist = [\"lil\",\"ft\",\"got\",\"get\",\"mv\",\"first\",\"vs\",\"highlights\",\"channel\",\"new\",\"official\",\"best\",\"check\",\"latest\",\"also\",\"thanks\",\"join\",\"¬ª\",\"new\",\"video\",\"content\",\"thanks\",\"¬ª\",\"tiktok\",\"s\",\"‚Äô\",\"‚Äì\",'‚Äú',\"im\",'‚Äù',\"v\",\"‚Äî\",\"w\",\"g\",\"‚Äò\",\"u\",\"‚ñ∫\",\"m\",\"i\",\"t\",\"de\",\"us\",\"instagram\",\"twitter\",\"videos\",\"subscribe\",\"go\",\"la\",\"every\",\"facebook\",\"watch\",\"youtube\",\"follow\",\"like\"]\n",
        "blacklist2 = [\"thi\",\"tak\",\"mo\",\"jo\",\"b\",\"minut\",\"mo\",\"ksi\",\"fnaf\",\"j\",\"vs\",\"x\",\" x\",\"x \",\"back\",\"short\",\"official\",\"el\",\"ofici\",\"gets\",\"l\",\"n\",\"v\",\"r\",\"el\",\"music\",\"minecraft\"]\n",
        "def newFunc(text):\n",
        "    list=[]\n",
        "    for i in text:\n",
        "        if i not in blacklist:\n",
        "            if i not in blacklist2:\n",
        "                list.append(i)\n",
        "    return list\n",
        "\n",
        "main_data['title'] = main_data['title'].progress_apply(lambda x : tokenise(x)).progress_apply(lambda x: newFunc(x)).progress_apply(lambda x: retokenise(x))\n",
        "main_data['title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2c1989b-9cc2-4c9a-bcb4-e651c884178c",
      "metadata": {
        "tags": [],
        "id": "a2c1989b-9cc2-4c9a-bcb4-e651c884178c"
      },
      "outputs": [],
      "source": [
        "after_data_cleaning = count_words(main_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc987b64-fea1-4c0e-9d54-b9855746cb6e",
      "metadata": {
        "tags": [],
        "id": "dc987b64-fea1-4c0e-9d54-b9855746cb6e"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(x=[\"before_data_cleaning\",\"after_data_cleaning\",\"Cleaned Stop Words\",\"The Cleaned Data\"],y=[before_data_cleaning,after_data_cleaning,(before_data_cleaning-after_cleaning_stopwords),(before_data_cleaning-after_data_cleaning)])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60901378-2c44-40eb-a031-c6fbe4e623b7",
      "metadata": {
        "tags": [],
        "id": "60901378-2c44-40eb-a031-c6fbe4e623b7"
      },
      "outputs": [],
      "source": [
        "top = Counter([item for titles in main_data['title'].progress_apply(lambda x : tokenise(x)) for item in titles])\n",
        "temp = pd.DataFrame(top.most_common(10))\n",
        "temp.columns = ['Common_words','count']\n",
        "temp.style.background_gradient(cmap='Blues')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29d67721-9e05-4c08-877e-04e060ae412d",
      "metadata": {
        "tags": [],
        "id": "29d67721-9e05-4c08-877e-04e060ae412d"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb4d2c3b-87ea-471f-9fb9-32172fed8059",
      "metadata": {
        "tags": [],
        "id": "bb4d2c3b-87ea-471f-9fb9-32172fed8059"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(temp, x=\"count\", y=\"Common_words\",title='Commmon Words in Selected Text',orientation='h', width=700, height=700,color='Common_words')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "956af25e-09ae-4976-acc7-ab86a607d3de",
      "metadata": {
        "tags": [],
        "id": "956af25e-09ae-4976-acc7-ab86a607d3de"
      },
      "outputs": [],
      "source": [
        "main_data.head()\n",
        "train_data = main_data.iloc[:,0]\n",
        "test_data = main_data.iloc[:,1]\n",
        "\n",
        "test_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32f6063c-728d-41b3-aaba-5ce14ff98823",
      "metadata": {
        "tags": [],
        "id": "32f6063c-728d-41b3-aaba-5ce14ff98823"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_data, test_data, random_state=0, train_size = .90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63668e36-d1bf-462a-828a-ee3e5c4395b7",
      "metadata": {
        "tags": [],
        "id": "63668e36-d1bf-462a-828a-ee3e5c4395b7"
      },
      "outputs": [],
      "source": [
        "x_prediction_data = X_test.copy()\n",
        "x_prediction = x_prediction_data.iloc[[1]]\n",
        "x_prediction.iloc[0] = \"travel the world \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd698d01-55be-4f2c-8cd6-3fdcedbecb0a",
      "metadata": {
        "tags": [],
        "id": "dd698d01-55be-4f2c-8cd6-3fdcedbecb0a"
      },
      "outputs": [],
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad59396e-5418-4679-8c5f-8e465261a6fc",
      "metadata": {
        "tags": [],
        "id": "ad59396e-5418-4679-8c5f-8e465261a6fc"
      },
      "outputs": [],
      "source": [
        "max_length = np.max(X_train.apply(lambda x: len(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bf66c0f-e189-4694-acb1-ba9859ba835b",
      "metadata": {
        "tags": [],
        "id": "5bf66c0f-e189-4694-acb1-ba9859ba835b"
      },
      "outputs": [],
      "source": [
        "max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6972c51-1861-4cb2-a0fa-1c6f87bb5dd4",
      "metadata": {
        "tags": [],
        "id": "c6972c51-1861-4cb2-a0fa-1c6f87bb5dd4"
      },
      "outputs": [],
      "source": [
        "X_train.max() # the longest sentences in our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed37748a-886b-44fd-96ad-1b65303c71b8",
      "metadata": {
        "tags": [],
        "id": "ed37748a-886b-44fd-96ad-1b65303c71b8"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e37b2a3-f85c-4b5a-87a0-969eee821632",
      "metadata": {
        "tags": [],
        "id": "6e37b2a3-f85c-4b5a-87a0-969eee821632"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "478a5e3d-d8dc-47fe-8d34-a109fb3286e4",
      "metadata": {
        "tags": [],
        "id": "478a5e3d-d8dc-47fe-8d34-a109fb3286e4"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer_predict = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "\n",
        "vocab_length = len(tokenizer.word_index) + 1\n",
        "\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_length, padding='post')\n",
        "\n",
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a94ec537-2066-427c-9cd6-4a4529cfa10d",
      "metadata": {
        "tags": [],
        "id": "a94ec537-2066-427c-9cd6-4a4529cfa10d"
      },
      "outputs": [],
      "source": [
        "print(\"Vocab length:\", vocab_length)\n",
        "print(\"Max sequence length:\", max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16f7a36b-1ed6-436d-83d1-fb8680c03ee0",
      "metadata": {
        "tags": [],
        "id": "16f7a36b-1ed6-436d-83d1-fb8680c03ee0"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9abc7873-b742-454e-8173-fe7c30530fd5",
      "metadata": {
        "tags": [],
        "id": "9abc7873-b742-454e-8173-fe7c30530fd5"
      },
      "outputs": [],
      "source": [
        " model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_length, embedding_dim, input_length=max_length),\n",
        "   # tf.keras.layers.Dense(vocab_length, activation='tanh'),\n",
        "    #tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True)),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(256, activation=tf.keras.activations.tanh),\n",
        "    tf.keras.layers.Dense(256, activation=tf.keras.activations.tanh),\n",
        "    tf.keras.layers.Dense(256, activation=tf.keras.activations.tanh),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(44, activation='softmax')\n",
        "])\n",
        "# opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94e73ddf-1252-4ed2-aa03-a1e4343c0f71",
      "metadata": {
        "tags": [],
        "id": "94e73ddf-1252-4ed2-aa03-a1e4343c0f71"
      },
      "outputs": [],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f98bd36-4ecb-4145-b15a-da838a482345",
      "metadata": {
        "tags": [],
        "id": "2f98bd36-4ecb-4145-b15a-da838a482345"
      },
      "outputs": [],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape ,x_prediction.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6709ca4a-44a1-4626-8ebd-2ff66c82aec2",
      "metadata": {
        "tags": [],
        "id": "6709ca4a-44a1-4626-8ebd-2ff66c82aec2"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c95d7ada-da38-49c3-8788-966c3699cbf5",
      "metadata": {
        "tags": [],
        "id": "c95d7ada-da38-49c3-8788-966c3699cbf5"
      },
      "outputs": [],
      "source": [
        "y_train.values.reshape(-1, 1),y_train.shape\n",
        "y_test.values.reshape(-1, 1),y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aee54f4f-c79d-4d4f-8d0c-df57d35df1af",
      "metadata": {
        "tags": [],
        "id": "aee54f4f-c79d-4d4f-8d0c-df57d35df1af"
      },
      "outputs": [],
      "source": [
        "max(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f1f9718-77a1-4545-90ca-7820c9d4fac0",
      "metadata": {
        "tags": [],
        "id": "2f1f9718-77a1-4545-90ca-7820c9d4fac0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, 44)\n",
        "y_test = to_categorical(y_test, 44)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f839c6ec-5c6b-4f79-aa41-3da93d000818",
      "metadata": {
        "tags": [],
        "id": "f839c6ec-5c6b-4f79-aa41-3da93d000818"
      },
      "outputs": [],
      "source": [
        "num_epochs = 15\n",
        "history = model.fit(X_train, y_train, epochs=num_epochs,validation_data=(X_test, y_test),batch_size =300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14b6caa4-476c-4bc9-a0c2-28bb7d161801",
      "metadata": {
        "tags": [],
        "id": "14b6caa4-476c-4bc9-a0c2-28bb7d161801"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "print(acc)\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8c05655-13c3-43d8-aa76-cd5a1a5a6fd1",
      "metadata": {
        "tags": [],
        "id": "b8c05655-13c3-43d8-aa76-cd5a1a5a6fd1"
      },
      "outputs": [],
      "source": [
        "wordList = pd.DataFrame(top.most_common())\n",
        "print(wordList[0])\n",
        "def checkWord(text):\n",
        "    response = []\n",
        "    print(text)\n",
        "    for word in text:\n",
        "        if word in wordList[0].tolist():\n",
        "            response.append(word)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "520bb9af-bd28-4c46-8d89-596861189915",
      "metadata": {
        "tags": [],
        "id": "520bb9af-bd28-4c46-8d89-596861189915"
      },
      "outputs": [],
      "source": [
        "def lexicon_normalize(list):\n",
        "    new_list = []\n",
        "    for i in list:\n",
        "\n",
        "        new_list.append(lexicon_normalization(i))\n",
        "        print(lexicon_normalization(i))\n",
        "    return new_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78e79d42-34ed-465c-8050-0299660187ef",
      "metadata": {
        "tags": [],
        "id": "78e79d42-34ed-465c-8050-0299660187ef"
      },
      "outputs": [],
      "source": [
        "x_prediction = x_prediction_data.iloc[[1]]\n",
        "\n",
        "# Change the input_text with your own sentence\n",
        "input_text = \"fear of living a good life\"\n",
        "\n",
        "input_text = tokenise(input_text)\n",
        "\n",
        "# We need to eliminate the words that not in our wordlist\n",
        "input_text = lexicon_normalize(input_text)\n",
        "\n",
        "input_text = checkWord(input_text)\n",
        "\n",
        "input_text = retokenise(input_text)\n",
        "\n",
        "x_prediction.iloc[0] = input_text\n",
        "\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qdr3qYdWoEAR"
      },
      "id": "Qdr3qYdWoEAR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf91547-4bd3-4ab0-9215-a4cde2c1f014",
      "metadata": {
        "tags": [],
        "id": "2cf91547-4bd3-4ab0-9215-a4cde2c1f014"
      },
      "outputs": [],
      "source": [
        "tokenizer_predict = Tokenizer()\n",
        "tokenizer_predict.fit_on_texts(x_prediction)\n",
        "\n",
        "x_prediction = tokenizer.texts_to_sequences(x_prediction)\n",
        "\n",
        "x_prediction = pad_sequences(x_prediction, maxlen=max_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9378435-66c8-44d0-af82-d401ced45f8c",
      "metadata": {
        "tags": [],
        "id": "f9378435-66c8-44d0-af82-d401ced45f8c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24f79370-90da-4d29-bbc7-be4790d2a025",
      "metadata": {
        "tags": [],
        "id": "24f79370-90da-4d29-bbc7-be4790d2a025"
      },
      "outputs": [],
      "source": [
        "probability_model = tf.keras.Sequential([model,tf.keras.layers.Softmax()])\n",
        "predictions = probability_model.predict(x_prediction)\n",
        "print(predictions)\n",
        "\n",
        "cat_dict[np.argmax(predictions)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0f82be1-766f-4d9a-bfd5-7a249789457e",
      "metadata": {
        "id": "d0f82be1-766f-4d9a-bfd5-7a249789457e"
      },
      "outputs": [],
      "source": [
        "print(f\"Accuracy on training data is:- {acc[-1]*100} %\")\n",
        "print(f\"Loss {loss[-1]*100}\")\n",
        "\n",
        "print(f\"Accuracy on validation data is:- {val_acc[-1]*100} %\")\n",
        "print(f\"Loss {val_loss[-1]*100}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc,'b',label='training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='validation acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(epochs, loss,'b',label='training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-A_ftUypgMWv"
      },
      "id": "-A_ftUypgMWv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "fYs37ibIgPIU"
      },
      "id": "fYs37ibIgPIU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('category_prediction.h5')"
      ],
      "metadata": {
        "id": "MYBwzJdJl0NO"
      },
      "id": "MYBwzJdJl0NO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = tf.keras.models.load_model('category_prediction.h5')"
      ],
      "metadata": {
        "id": "v6xKW3emmfXw"
      },
      "id": "v6xKW3emmfXw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('category_pickle.pkl', 'wb') as f:\n",
        "    pickle.dump(loaded_model, f)"
      ],
      "metadata": {
        "id": "7TrxcEgEmjTu"
      },
      "id": "7TrxcEgEmjTu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nFt77a5poF6S"
      },
      "id": "nFt77a5poF6S",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sagemaker-distribution:Python",
      "language": "python",
      "name": "conda-env-sagemaker-distribution-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}